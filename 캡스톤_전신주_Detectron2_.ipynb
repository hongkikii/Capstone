{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNfllRZKTWzkF9GLI8uo1O5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hongkikii/Capstone/blob/main/%EC%BA%A1%EC%8A%A4%ED%86%A4_%EC%A0%84%EC%8B%A0%EC%A3%BC_Detectron2_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install detectron2"
      ],
      "metadata": {
        "id": "V8T1pQXi1RCX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qwiQggwqzbIv"
      },
      "outputs": [],
      "source": [
        "!python -m pip install pyyaml==5.1\n",
        "import sys, os, distutils.core\n",
        "# Note: This is a faster way to install detectron2 in Colab, but it does not include all functionalities (e.g. compiled operators).\n",
        "# See https://detectron2.readthedocs.io/tutorials/install.html for full installation instructions\n",
        "!git clone 'https://github.com/facebookresearch/detectron2'\n",
        "dist = distutils.core.run_setup(\"./detectron2/setup.py\")\n",
        "!python -m pip install {' '.join([f\"'{x}'\" for x in dist.install_requires])}\n",
        "sys.path.insert(0, os.path.abspath('./detectron2'))\n",
        "\n",
        "# Properly install detectron2. (Please do not install twice in both ways)\n",
        "# !python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Some basic setup:\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import os, json, cv2, random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog"
      ],
      "metadata": {
        "id": "20O7Adgm1VA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run a pre-trained detectron2 model"
      ],
      "metadata": {
        "id": "M0qtBiJf1Ugo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O input.jpg\n",
        "im = cv2.imread(\"./input.jpg\")\n",
        "cv2_imshow(im)"
      ],
      "metadata": {
        "id": "MoKHvU4P1Wzl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cfg = get_cfg()\n",
        "# add project-specific config (e.g., TensorMask) here if you're not running a model in detectron2's core library\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model\n",
        "# Find a model from detectron2's model zoo. You can use the https://dl.fbaipublicfiles... url as well\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
        "predictor = DefaultPredictor(cfg)\n",
        "outputs = predictor(im)"
      ],
      "metadata": {
        "id": "_L_eX2H11bWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# look at the outputs. See https://detectron2.readthedocs.io/tutorials/models.html#model-output-format for specification\n",
        "print(outputs[\"instances\"].pred_classes)\n",
        "print(outputs[\"instances\"].pred_boxes)"
      ],
      "metadata": {
        "id": "x6lm2kky1dkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We can use `Visualizer` to draw the predictions on the image.\n",
        "v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
        "out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "cv2_imshow(out.get_image()[:, :, ::-1])"
      ],
      "metadata": {
        "id": "9sBkFo5x1eSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train on a custom dataset"
      ],
      "metadata": {
        "id": "esU9u6wl1RBa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare the dataset"
      ],
      "metadata": {
        "id": "U1QcwdyE1kkF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "NTU9mpQw1fWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "drive_path = '/content/drive/My Drive/pole'\n",
        "\n",
        "destination_path = '/content/pole'\n",
        "\n",
        "if os.path.exists(destination_path):\n",
        "    shutil.rmtree(destination_path)\n",
        "\n",
        "shutil.copytree(drive_path, destination_path)"
      ],
      "metadata": {
        "id": "kxIjBxAI1lx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
        "from detectron2.structures import BoxMode\n",
        "import os\n",
        "import json\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def get_pole_dicts(img_dir):\n",
        "    json_file = os.path.join(img_dir, \"instances_default.json\")\n",
        "    with open(json_file, encoding='utf-8') as f:\n",
        "        dataset_dicts = json.load(f)\n",
        "\n",
        "    # Images list\n",
        "    images = {img[\"id\"]: img for img in dataset_dicts[\"images\"]}\n",
        "\n",
        "    # Annotations list\n",
        "    annotations = dataset_dicts[\"annotations\"]\n",
        "\n",
        "    # Categories\n",
        "    categories = {cat[\"id\"]: cat[\"name\"] for cat in dataset_dicts[\"categories\"]}\n",
        "\n",
        "    # Create the dataset dicts in Detectron2 format\n",
        "    dataset_dicts = []\n",
        "    for image_id, image in images.items():\n",
        "        record = {}\n",
        "        record[\"file_name\"] = os.path.join(\"/content/pole/images\", image[\"file_name\"])\n",
        "        record[\"image_id\"] = image_id\n",
        "        record[\"height\"] = image[\"height\"]\n",
        "        record[\"width\"] = image[\"width\"]\n",
        "\n",
        "        objs = []\n",
        "        for ann in annotations:\n",
        "            if ann[\"image_id\"] == image_id:\n",
        "                obj = {\n",
        "                    \"bbox\": ann[\"bbox\"],\n",
        "                    \"bbox_mode\": BoxMode.XYWH_ABS,\n",
        "                    \"segmentation\": ann[\"segmentation\"],\n",
        "                    \"category_id\": ann[\"category_id\"] - 1,  # Detectron2 uses 0-indexed category IDs\n",
        "                    \"iscrowd\": ann.get(\"iscrowd\", 0),\n",
        "                }\n",
        "                objs.append(obj)\n",
        "        record[\"annotations\"] = objs\n",
        "        dataset_dicts.append(record)\n",
        "\n",
        "    return dataset_dicts\n",
        "\n",
        "for d in [\"train\", \"val\"]:\n",
        "    dataset_name = \"pole_\" + d\n",
        "    if dataset_name in DatasetCatalog.list():\n",
        "        DatasetCatalog.remove(dataset_name)\n",
        "        MetadataCatalog.remove(dataset_name)\n",
        "\n",
        "categories = [\n",
        "    {\"id\": 1, \"name\": \"폴리머현수\", \"supercategory\": \"\"},\n",
        "    {\"id\": 2, \"name\": \"접속개소\", \"supercategory\": \"\"},\n",
        "    {\"id\": 3, \"name\": \"LA\", \"supercategory\": \"\"},\n",
        "    {\"id\": 4, \"name\": \"TR\", \"supercategory\": \"\"},\n",
        "    {\"id\": 5, \"name\": \"폴리머LP\", \"supercategory\": \"\"}\n",
        "]\n",
        "\n",
        "thing_classes = [cat[\"name\"] for cat in categories]\n",
        "\n",
        "dataset_dicts = get_pole_dicts(\"/content/pole/annotations\")\n",
        "\n",
        "random.shuffle(dataset_dicts)\n",
        "split_ratio = 0.8\n",
        "train_size = int(len(dataset_dicts) * split_ratio)\n",
        "train_dicts = dataset_dicts[:train_size]\n",
        "val_dicts = dataset_dicts[train_size:]\n",
        "\n",
        "DatasetCatalog.register(\"pole_train\", lambda: train_dicts)\n",
        "MetadataCatalog.get(\"pole_train\").set(thing_classes=thing_classes)\n",
        "\n",
        "DatasetCatalog.register(\"pole_val\", lambda: val_dicts)\n",
        "MetadataCatalog.get(\"pole_val\").set(thing_classes=thing_classes)"
      ],
      "metadata": {
        "id": "uwNuKKrD1nFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for d in random.sample(train_dicts, 3):\n",
        "    img = cv2.imread(d[\"file_name\"])\n",
        "    visualizer = Visualizer(img[:, :, ::-1], metadata=MetadataCatalog.get(\"pole_train\"), scale=0.5)\n",
        "    out = visualizer.draw_dataset_dict(d)\n",
        "    cv2_imshow(out.get_image()[:, :, ::-1])"
      ],
      "metadata": {
        "id": "axwsC3P51p61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train!"
      ],
      "metadata": {
        "id": "n2vraSw91uye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.engine import DefaultTrainer\n",
        "\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg.DATASETS.TRAIN = (\"pole_train\",)\n",
        "cfg.DATASETS.TEST = ()\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
        "cfg.SOLVER.IMS_PER_BATCH = 2  # This is the real \"batch size\" commonly known to deep learning people\n",
        "cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\n",
        "cfg.SOLVER.MAX_ITER = 5400    # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\n",
        "cfg.SOLVER.STEPS = []        # do not decay learning rate\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # The \"RoIHead batch size\". 128 is faster, and good enough for this toy dataset (default: 512)\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 5  # only has one class (ballon). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n",
        "# NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.\n",
        "\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "trainer = DefaultTrainer(cfg)\n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "eHPo0Pdp1tfh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at training curves in tensorboard:\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir output"
      ],
      "metadata": {
        "id": "w2CBIBrA1yX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inference & evaluation using the trained model"
      ],
      "metadata": {
        "id": "6dkTpI1r10I3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inference should use the config with parameters that are used in training\n",
        "# cfg now already contains everything we've set previously. We changed it a little bit for inference:\n",
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set a custom testing threshold\n",
        "predictor = DefaultPredictor(cfg)"
      ],
      "metadata": {
        "id": "ZFvyNqvf1yYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.utils.visualizer import ColorMode\n",
        "dataset_dicts = get_pole_dicts(\"/content/pole/annotations\")\n",
        "for d in random.sample(dataset_dicts, 10):\n",
        "    im = cv2.imread(d[\"file_name\"])\n",
        "    outputs = predictor(im)  # format is documented at https://detectron2.readthedocs.io/tutorials/models.html#model-output-format\n",
        "    v = Visualizer(im[:, :, ::-1],\n",
        "                   metadata=MetadataCatalog.get(\"pole_train\"),\n",
        "                   scale=0.5,\n",
        "                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels. This option is only available for segmentation models\n",
        "    )\n",
        "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "    cv2_imshow(out.get_image()[:, :, ::-1])"
      ],
      "metadata": {
        "id": "kgXkjbQ811kK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}